# ğŸ¥ Pipeline ETL de NormalizaciÃ³n de Datos ClÃ­nicos

![Python](https://img.shields.io/badge/Python-3.9-blue)
![Docker](https://img.shields.io/badge/Docker-Enabled-2496ED)
![Postgres](https://img.shields.io/badge/Postgres-13-336791)
![Status](https://img.shields.io/badge/Status-Completed-green)

## ğŸ“‹ DescripciÃ³n del Proyecto
Este proyecto implementa una soluciÃ³n de **IngenierÃ­a de Datos** para resolver un problema de fragmentaciÃ³n de informaciÃ³n en un entorno hospitalario.

Se simula un escenario donde 3 sedes clÃ­nicas reportan resultados de laboratorio en formatos heterogÃ©neos (CSV, Excel, JSON "sucia"). El objetivo es ingestar, normalizar y centralizar estos datos en un **Data Warehouse (PostgreSQL)** para permitir anÃ¡lisis clÃ­nicos unificados y detecciÃ³n de anomalÃ­as.

### ğŸ¯ Objetivos TÃ©cnicos
* **Ingesta Multi-fuente:** Procesamiento de archivos planos y semi-estructurados.
* **Calidad de Datos:** Limpieza de valores nulos, estandarizaciÃ³n de unidades de medida (mg/dL) y normalizaciÃ³n de esquemas.
* **Infraestructura como CÃ³digo:** Despliegue de base de datos utilizando contenedores Docker para garantizar reproducibilidad.

## ğŸ—ï¸ Arquitectura y Tech Stack

* **Lenguaje:** Python 3.9 (Pandas, SQLAlchemy, Faker).
* **Base de Datos:** PostgreSQL 13 (Corriendo en Docker).
* **ContenedorizaciÃ³n:** Docker & Docker Compose.
* **OrquestaciÃ³n:** Scripts modulares de Python.

---

## ğŸ“‚ Estructura del Proyecto

```bash
biomed-lab-etl/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                   # Landing zone para archivos crudos (CSV, XLSX, JSON)
â”œâ”€â”€ docs/                      # DocumentaciÃ³n de arquitectura y decisiones
â”œâ”€â”€ pg_data/                   # Persistencia de datos de Postgres (Ignorado por Git)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 00_generar_datos_sucios.py   # Generador de data sintÃ©tica (Faker)
â”‚   â””â”€â”€ 01_etl_pipeline.py           # Script principal ETL
â”œâ”€â”€ docker-compose.yml         # DefiniciÃ³n de infraestructura
â””â”€â”€ requirements.txt           # Dependencias de Python
```


## ğŸš€ GuÃ­a de InstalaciÃ³n y EjecuciÃ³n

Si deseas replicar este proyecto en tu entorno local, sigue estos pasos:

### 1. Prerrequisitos
* **Docker Desktop** instalado y ejecutÃ¡ndose.
* **Python 3.8+** instalado.
* **Git** instalado.

### 2. Clonar el repositorio e instalar dependencias
```bash
git clone [https://github.com/TU_USUARIO/biomed-lab-etl.git](https://github.com/TU_USUARIO/biomed-lab-etl.git)
cd biomed-lab-etl
```

# Se recomienda usar entorno virtual
pip install pandas sqlalchemy psycopg2-binary faker openpyxl


### 3. Despliegue de Infraestructura (Base de Datos)
Ejecutar el contenedor de Docker que levantarÃ¡ la instancia de PostgreSQL.
```bash
docker-compose up -d
```

### 4. EjecuciÃ³n del Pipeline
El proyecto incluye un generador de datos para simular el entorno hospitalario.

**Paso A: Generar datos de prueba**
```bash
python scripts/00_generar_datos_sucios.py
```

**Paso B: Correr el proceso ETL**
```bash
python scripts/01_etl_pipeline.py
```

## ğŸ“Š Resultados e Impacto
Tras la ejecuciÃ³n del pipeline y el anÃ¡lisis de los datos centralizados, se identificÃ³ un **hallazgo crÃ­tico**:

> ğŸš¨ **AnomalÃ­a Detectada:** La **Sede Sur** presenta un promedio de glucosa de **177.5 mg/dL**, significativamente superior al promedio de la Sede Central (101.3 mg/dL).

Esta discrepancia, visible solo tras la unificaciÃ³n de los datos, sugiere una posible descalibraciÃ³n en los equipos de mediciÃ³n de dicha sede o un factor de riesgo poblacional no atendido.

---

## ğŸ‘¤ Autor
**Victor Lopez**
*Ingeniero BiomÃ©dico & Analytics Engineer*