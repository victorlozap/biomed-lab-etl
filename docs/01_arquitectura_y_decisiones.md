# üè• Proyecto: Centralizaci√≥n de Datos de Laboratorio (Biomed ETL)

## 1. Contexto del Negocio (El "Por qu√©")
**Problema:** Un laboratorio cl√≠nico tiene 3 sedes. Cada sede genera reportes de ex√°menes en archivos sucios (Excel/CSV) con formatos distintos. Actualmente, el an√°lisis se hace manual, lo que genera errores y demora la entrega de reportes gerenciales.

**Objetivo:** Crear un repositorio centralizado (Data Warehouse) que ingeste, limpie y estandarice estos datos autom√°ticamente para permitir an√°lisis en tiempo real.

---------

## 2. Decisiones de Arquitectura (El "C√≥mo" y el "Para qu√©")

### üèóÔ∏è Decisi√≥n 1: Uso de Docker
* **¬øQu√© es?**: Una herramienta de contenerizaci√≥n.
* **¬øPor qu√© lo usamos?**:
    * **Reproducibilidad:** Evita el problema de "en mi m√°quina funciona". El entorno es id√©ntico en desarrollo y producci√≥n.
    * **Aislamiento:** No ensuciamos el sistema operativo (Windows) instalando m√∫ltiples versiones de bases de datos.
    * **Limpieza:** Si el proyecto falla, borramos el contenedor y el sistema queda intacto.

---------

### üóÑÔ∏è Decisi√≥n 2: PostgreSQL como Data Warehouse
* **¬øQu√© es?**: Base de datos relacional (RDBMS) open source.
* **¬øPor qu√© lo elegimos sobre MySQL?**:
    * **Est√°ndar en Data:** Es la base tecnol√≥gica de Redshift (AWS) y similar a BigQuery (Google).
    * **Manejo de Datos Complejos:** Mejor soporte nativo para JSON (muy com√∫n en formatos m√©dicos como FHIR).
    * **Anal√≠tica:** Tiene funciones de ventana (Window Functions) m√°s robustas para an√°lisis estad√≠stico.

---------

### üêç Decisi√≥n 3: Python como Motor de Ingesta
* **¬øQu√© es?**: Lenguaje de programaci√≥n de prop√≥sito general.
* **¬øPor qu√© lo usamos?**:
    * **Ecosistema de Datos:** Librer√≠as como `Pandas` son el est√°ndar de oro para manipulaci√≥n tabular.
    * **Conectividad:** `SQLAlchemy` permite interactuar con bases de datos (SQL) usando objetos de Python, abstrayendo la complejidad de SQL puro.
    * **Faker:** Usaremos la librer√≠a `Faker` para generar datos sint√©ticos que simulan informaci√≥n de pacientes (PII) sin comprometer datos reales, cumpliendo normas √©ticas (HIPAA/GDPR).

---------

## 3. Estrategia de Transformaci√≥n (ETL)

El desaf√≠o es unificar 3 fuentes con esquemas distintos en una **Tabla Maestra**.

### Esquema de Salida (Target Schema)
Independientemente de c√≥mo llegue el dato, en nuestra base de datos (Postgres) se guardar√° siempre con este formato est√°ndar:

| Columna | Tipo SQL | Descripci√≥n |
| :--- | :--- | :--- |
| `id_paciente` | TEXT | Identificador √∫nico del paciente (an√≥nimo) |
| `fecha_muestra` | TIMESTAMP | Fecha y hora estandarizada de la toma |
| `nivel_glucosa` | INTEGER | Valor num√©rico limpio (sin texto "mg/dL") |
| `fuente_sede` | TEXT | Para trazabilidad (Saber de qu√© archivo vino) |

### Reglas de Limpieza
1. **Sede Norte (Excel):** Renombrar `Glucose Level` -> `nivel_glucosa`.
2. **Sede Sur (JSON):** Eliminar la unidad de medida " mg/dL" del texto y convertir a n√∫mero. Manejar valores nulos (descartar o marcar).

---------

## 4. Implementaci√≥n del Pipeline ETL

### Tecnolog√≠a Utilizada
Se construy√≥ un script en Python (`01_etl_pipeline.py`) que act√∫a como orquestador del flujo de datos.

### Fases del Proceso
#### 1. Extracci√≥n (Extract)
* Se utilizan conectores espec√≠ficos de Pandas para cada formato:
    * `read_csv` para Sede Central.
    * `read_excel` (motor openpyxl) para Sede Norte.
    * `read_json` para Sede Sur.

#### 2. Transformaci√≥n (Transform)
Se aplica **l√≥gica de negocio** para normalizar los datos antes de que toquen la base de datos:
* **Estandarizaci√≥n de Esquema:** Se renombran columnas dispares (`Glucose Level`, `resultado_glucosa`) al est√°ndar `nivel_glucosa`.
* **Limpieza de Datos (Data Cleaning):**
    * En la Sede Sur, se eliminan sufijos de texto (" mg/dL") para convertir el campo a num√©rico (`Integer`).
    * Se eliminan registros nulos que no aportan valor cl√≠nico.
* **Enriquecimiento:** Se agrega la columna `fuente_sede` para mantener la trazabilidad del dato (Data Lineage).

#### 3. Carga (Load)
* Se utiliza `SQLAlchemy` para crear una conexi√≥n segura con el contenedor Docker.
* Modo de carga: `if_exists='replace'` (para desarrollo/pruebas). En producci√≥n se cambiar√≠a a `'append'` (incremental).

### Resultado
* **Input:** 3 archivos heterog√©neos y sucios.
* **Output:** Tabla `hechos_glucosa` en PostgreSQL con esquema unificado y tipos de datos correctos.